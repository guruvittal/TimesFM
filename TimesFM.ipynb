{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1pF1j5D0B8ehW_5KZZTtG4ZVJW_aBseyB",
      "authorship_tag": "ABX9TyP9m63Szj4UxNDXfyBbmtbe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dfd13d86fd884a998f83c467bb4f0ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d95b0787fe914221b85c074b8063f26f",
              "IPY_MODEL_5856951de2fc4489ab13d022cfd308d0",
              "IPY_MODEL_cbe4ba5e8b5448caababe9978579c365"
            ],
            "layout": "IPY_MODEL_6048680688ae440eae9a15c97d41a89f"
          }
        },
        "d95b0787fe914221b85c074b8063f26f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9989d5181a83408b9863f7a9f35e90a9",
            "placeholder": "​",
            "style": "IPY_MODEL_768ee4f70ff3452d8fb20e5a081b2834",
            "value": "Fetching 5 files: 100%"
          }
        },
        "5856951de2fc4489ab13d022cfd308d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46e976374d974f6e8f5f49a41600c575",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fc608bce88c4e7496fc32c342ea2174",
            "value": 5
          }
        },
        "cbe4ba5e8b5448caababe9978579c365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1a125d226414cd18b213878b5c71ebb",
            "placeholder": "​",
            "style": "IPY_MODEL_a0ef489538b645678e0c79ceff6de775",
            "value": " 5/5 [00:00&lt;00:00, 160.48it/s]"
          }
        },
        "6048680688ae440eae9a15c97d41a89f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9989d5181a83408b9863f7a9f35e90a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768ee4f70ff3452d8fb20e5a081b2834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46e976374d974f6e8f5f49a41600c575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc608bce88c4e7496fc32c342ea2174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1a125d226414cd18b213878b5c71ebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0ef489538b645678e0c79ceff6de775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guruvittal/TimesFM/blob/main/TimesFM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rAGkxuhNaYst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f0944f-16bd-4542-d4ba-a8657b99f1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "installing package einshape\n",
            "installing package paxml\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.2/440.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m686.8/686.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.0/168.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.5/772.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.8/577.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.1/353.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.5/164.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: The script qtpy is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script f2py is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script sacrebleu is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script tfds is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script tfds is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script tensorboard is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script seqio_cache_tasks is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts t5_cache_tasks, t5_inspect_tasks and t5_mesh_transformer are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0minstalling package praxis\n",
            "installing package fastapi\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33m  WARNING: The script dotenv is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script watchfiles is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script uvicorn is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script email_validator is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script typer is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script httpx is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script fastapi is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0minstalling package docker\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hinstalling package utilsforecast\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title Install Libraries\n",
        "packages = [\n",
        "    ('einshape', 'einshape'),\n",
        "    ('paxml', 'paxml'),\n",
        "    ('praxis','praxis'),\n",
        "    ('jax','jax'),\n",
        "    ('fastapi','fastapi'),\n",
        "    ('docker','docker'),\n",
        "    ('utilsforecast','utilsforecast'),\n",
        "    ('numpy','numpy'),\n",
        "    ('pandas', 'pandas')\n",
        "]\n",
        "\n",
        "import importlib\n",
        "install = False\n",
        "for package in packages:\n",
        "    if not importlib.util.find_spec(package[0]):\n",
        "        print(f'installing package {package[1]}')\n",
        "        install = True\n",
        "        !pip install {package[1]} -U --quiet --user\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GCP Constants\n",
        "PROJECT_ID = \"argolis-project-340214\"   # @param {type: \"string\"}\n",
        "LOCATION = 'us-central1' # @param {type: \"string\"}\n",
        "STAGING_BUCKET = 'firstargolisbucket' # @param {type: \"string\"}"
      ],
      "metadata": {
        "id": "RGH50Bi6Kf3L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Auth\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth as google_auth\n",
        "  google_auth.authenticate_user()"
      ],
      "metadata": {
        "id": "3v7_HmtKLbVM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "from google.colab import files\n",
        "files.view('/content')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FAv9z42Bzs0q",
        "outputId": "7fa441e9-b6ef-4278-cf84-f2cc9a2bd431"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      ((filepath) => {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content\")"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/google-research/timesfm"
      ],
      "metadata": {
        "id": "tSARdejt7XnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list -v\n"
      ],
      "metadata": {
        "id": "Fy0IgJUuwf9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform.prediction import LocalModel\n",
        "from google.cloud.aiplatform.docker_utils import build\n",
        "from huggingface_hub.hf_api import HfFolder\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "import configparser\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "aiplatform.init(project=PROJECT_ID,location=LOCATION, staging_bucket=STAGING_BUCKET)\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "config.read('config.ini')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHe3CZTSI7ys",
        "outputId": "a1332da6-220c-46ff-80b2-8b3156a091af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Setup HuggingFace (TimesFM)\n",
        "\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import HfFolder\n",
        "from huggingface_hub import login\n",
        "\n",
        "# You will need to change these variables\n",
        "token = userdata.get('HF_TOKEN') #@param\n",
        "\n",
        "login(token)\n",
        "\n",
        "repo_id = \"google/timesfm-1.0-200m\"\n",
        "folder = HfFolder()\n",
        "\n",
        "# Authenticate with parameters\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeMop-fCvCoF",
        "outputId": "597209eb-cbd7-4d11-80b0-514677bd14c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the structure to the file we will create\n",
        "config.add_section('HuggingFace')\n",
        "config.set('HuggingFace', 'hf_access_token', token)\n",
        "with open(r\"config.ini\", 'w') as configfile:\n",
        "    config.write(configfile)"
      ],
      "metadata": {
        "id": "KQkjQQqUOi3y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HfFolder.save_token(config['HuggingFace']['hf_access_token'])"
      ],
      "metadata": {
        "id": "2Og4mqvdNVOJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TIMESFM_MODEL_NAME = \"google/timesfm-1.0-200m\"\n",
        "GCS_TIMESFM_CKPT_PATH = f\"{STAGING_BUCKET}/googleio24/models/timesfm/\"\n",
        "\n",
        "LOCAL_TIMESFM_CKPT_PATH = \"models/timesfm/checkpoints_flax/\"\n",
        "PATH_TO_THE_SOURCE_DIR = \"src/timesfm_serving\"\n",
        "\n",
        "PATH_TO_REQUIREMENTS_TXT = f\"{PATH_TO_THE_SOURCE_DIR}/requirements.txt\"\n",
        "\n",
        "ARTIFACT_REPOSITORY = \"googleio24\"\n",
        "TIMESFM_IMAGE = \"timesfm-001-200m\"\n",
        "\n",
        "TIMESFM_IMAGE_URI = f\"{LOCATION}-docker.pkg.dev/{PROJECT_ID}/{ARTIFACT_REPOSITORY}/{TIMESFM_IMAGE}\"\n",
        "TIMESFM_MODEL_DISPLAY_NAME = \"io24-timesfm-001-200m\"\n",
        "\n",
        "TIMESFM_ENDPOINT_DISPLAY_NAME = f\"{TIMESFM_MODEL_DISPLAY_NAME}_endpoint\"\n",
        "\n",
        "BASE_IMAGE = \"python:3.10\"\n",
        "DEFAULT_HTTP_PORT = 8501\n",
        "\n",
        "DEFAULT_PREDICT_ROUTE = \"/predict\"\n",
        "DEFAULT_HEALTH_ROUTE = \"/health\""
      ],
      "metadata": {
        "id": "J__AurC2Qt93"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PATH_TO_THE_SOURCE_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpZvGUdr14G5",
        "outputId": "975e1f38-10d4-452d-a96b-da2d88d7df14"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src/timesfm_serving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p $PATH_TO_THE_SOURCE_DIR\n",
        "!touch $PATH_TO_THE_SOURCE_DIR/__init__.py\n",
        "\n",
        "#Set project\n",
        "!gcloud config set project $PROJECT_ID\n",
        "\n",
        "# enable artifact registry service\n",
        "!gcloud services enable artifactregistry.googleapis.com\n",
        "\n",
        "# create docker repository in artifact registry\n",
        "!gcloud artifacts repositories create $ARTIFACT_REPOSITORY \\\n",
        "    --repository-format=docker \\\n",
        "    --location=$LOCATION \\\n",
        "    --description=\"Artifact repository with TimesFM\"\n",
        "\n",
        "# configure auth for docker\n",
        "!gcloud auth configure-docker $LOCATION-docker.pkg.dev --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxKw_0_jRbMN",
        "outputId": "e2c4d44a-b01b-470e-f0e7-8d174eb236a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n",
            "\u001b[1;33mWARNING:\u001b[0m `docker` not in system PATH.\n",
            "`docker` and `docker-credential-gcloud` need to be in the same PATH in order to work correctly together.\n",
            "gcloud's Docker credential helper can be configured but it will not work until this is corrected.\n",
            "Adding credentials for: us-central1-docker.pkg.dev\n",
            "Docker configuration file updated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(GCS_TIMESFM_CKPT_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_JnomX1fHrL",
        "outputId": "57d840b5-eb3b-4101-d0f8-95d40219b5c5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://firstargolisbucket/models/timesfm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sync the 'checkpoints' subdirectory to Google Cloud Storage (GCS)\n",
        "GCS_TIMESFM_CKPT_PATH = f\"gs://{STAGING_BUCKET}/models/timesfm\"  # Replace with your GCS bucket\n"
      ],
      "metadata": {
        "id": "lB_qEypmqg60"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Getting HF model:\", HF_TIMESFM_MODEL_NAME)\n",
        "# Create a local directory to store the model checkpoint files\n",
        "LOCAL_TIMESFM_CKPT_PATH=\"models/timesfm/checkpoints_flax\"\n",
        "!mkdir -p $LOCAL_TIMESFM_CKPT_PATH\n",
        "\n",
        "# Download the model checkpoint files from the Hugging Face Hub\n",
        "#HF_TIMESFM_MODEL_NAME = \"google/timesfm-1.0-200m\"  # Hugging Face model identifier\n",
        "snapshot_download(\n",
        "    repo_id=HF_TIMESFM_MODEL_NAME,\n",
        "    local_dir=LOCAL_TIMESFM_CKPT_PATH,\n",
        "    token=True  # Set to True if the model requires authentication\n",
        ")\n",
        "\n",
        "!gsutil -m cp -r $LOCAL_TIMESFM_CKPT_PATH/checkpoints $GCS_TIMESFM_CKPT_PATH\n",
        "\n",
        "# Verify that the files were uploaded to GCS\n",
        "!gsutil ls -r $GCS_TIMESFM_CKPT_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815,
          "referenced_widgets": [
            "dfd13d86fd884a998f83c467bb4f0ebd",
            "d95b0787fe914221b85c074b8063f26f",
            "5856951de2fc4489ab13d022cfd308d0",
            "cbe4ba5e8b5448caababe9978579c365",
            "6048680688ae440eae9a15c97d41a89f",
            "9989d5181a83408b9863f7a9f35e90a9",
            "768ee4f70ff3452d8fb20e5a081b2834",
            "46e976374d974f6e8f5f49a41600c575",
            "8fc608bce88c4e7496fc32c342ea2174",
            "c1a125d226414cd18b213878b5c71ebb",
            "a0ef489538b645678e0c79ceff6de775"
          ]
        },
        "id": "k-Hi6goQYn5a",
        "outputId": "7db77796-59a2-4d24-ed55-b4dff7d6f84a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting HF model: google/timesfm-1.0-200m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfd13d86fd884a998f83c467bb4f0ebd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://models/timesfm/checkpoints_flax/checkpoints/checkpoint_1100000/metadata/metadata [Content-Type=application/octet-stream]...\n",
            "Copying file://models/timesfm/checkpoints_flax/checkpoints/checkpoint_1100000/descriptor/descriptor.pbtxt [Content-Type=application/octet-stream]...\n",
            "/ [0/3 files][    0.0 B/776.6 MiB]   0% Done                                    \r/ [0/3 files][    0.0 B/776.6 MiB]   0% Done                                    \rCopying file://models/timesfm/checkpoints_flax/checkpoints/checkpoint_1100000/state/checkpoint [Content-Type=application/octet-stream]...\n",
            "/ [0/3 files][    0.0 B/776.6 MiB]   0% Done                                    \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "-\n",
            "Operation completed over 3 objects/776.6 MiB.                                    \n",
            "gs://firstargolisbucket/models/timesfm/:\n",
            "\n",
            "gs://firstargolisbucket/models/timesfm/checkpoint_1100000/:\n",
            "\n",
            "gs://firstargolisbucket/models/timesfm/checkpoint_1100000/descriptor/:\n",
            "gs://firstargolisbucket/models/timesfm/checkpoint_1100000/descriptor/descriptor.pbtxt\n",
            "\n",
            "gs://firstargolisbucket/models/timesfm/checkpoint_1100000/metadata/:\n",
            "gs://firstargolisbucket/models/timesfm/checkpoint_1100000/metadata/metadata\n",
            "\n",
            "gs://firstargolisbucket/models/timesfm/checkpoint_1100000/state/:\n",
            "gs://firstargolisbucket/models/timesfm/checkpoint_1100000/state/checkpoint\n",
            "\n",
            "gs://firstargolisbucket/models/timesfm/checkpoints/:\n",
            "\n",
            "gs://firstargolisbucket/models/timesfm/checkpoints/checkpoint_1100000/:\n",
            "\n",
            "gs://firstargolisbucket/models/timesfm/checkpoints/checkpoint_1100000/descriptor/:\n",
            "gs://firstargolisbucket/models/timesfm/checkpoints/checkpoint_1100000/descriptor/descriptor.pbtxt\n",
            "\n",
            "gs://firstargolisbucket/models/timesfm/checkpoints/checkpoint_1100000/metadata/:\n",
            "gs://firstargolisbucket/models/timesfm/checkpoints/checkpoint_1100000/metadata/metadata\n",
            "\n",
            "gs://firstargolisbucket/models/timesfm/checkpoints/checkpoint_1100000/state/:\n",
            "gs://firstargolisbucket/models/timesfm/checkpoints/checkpoint_1100000/state/checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create a Custom Predictor\n",
        "\n",
        "%%writefile $PATH_TO_THE_SOURCE_DIR/predictor.py\n",
        "\"\"\"Adapts a pretrained time-series foundation model TimesFM to the CPR framework.\n",
        "Documentation for the model is here:\n",
        "                           https://github.com/google-research/timesfm\n",
        "\n",
        "Model checkpoints can be found here:\n",
        "                           https://huggingface.co/google/timesfm-1.0-200m\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from typing import Sequence, Any, Tuple, List, Dict, Union\n",
        "\n",
        "from fastapi import HTTPException  # For handling API errors\n",
        "from google.cloud.aiplatform.utils import prediction_utils  # Google Cloud AI Platform utilities\n",
        "\n",
        "# from google.cloud.aiplatform import prediction as cpr  # Commented out, might be used later\n",
        "\n",
        "import pandas as pd  # For data manipulation\n",
        "import numpy as np   # For numerical operations\n",
        "\n",
        "from paxml import checkpoints  # For loading model checkpoints\n",
        "import timesfm  # The TimesFM model library\n",
        "import jax.numpy as jnp\n",
        "\n",
        "# JAX Configuration (Accelerated Linear Algebra)\n",
        "from jax._src import config\n",
        "config.update(\"jax_platforms\", \"\")  # Configures JAX to use available hardware accelerators (GPUs, TPUs)\n",
        "\n",
        "\n",
        "# --- PREDICTION CLASS ---\n",
        "# (Code likely continues from here, defining the predictor class and its methods)\n",
        "\n",
        "class TimesFMPredictor:\n",
        "    \"\"\"Predictor class for Time Series Foundation Model (TimesFM).\"\"\"\n",
        "    TIMESFM_MODEL_NAME = os.getenv(\"TIMESFM_MODEL_NAME\", default=\"timesfm-1.0-200m\")\n",
        "    CONTEXT_LEN = 512\n",
        "    HORIZON_LEN = 128\n",
        "    INPUT_PATCH_LEN = 32\n",
        "    OUTPUT_PATCH_LEN = 128\n",
        "    NUM_LAYERS = 20\n",
        "    MODEL_DIMS = 1280\n",
        "    BACKEND = \"cpu\"  # or \"gpu\" if available\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the predictor class.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self, artifacts_uri: str = \"\"):\n",
        "        \"\"\"Initializes the model and preprocessing transforms.\n",
        "\n",
        "        Args:\n",
        "            artifacts_uri: Directory where state dict is stored. Can be a\n",
        "                GCS URI or local path.\n",
        "        \"\"\"\n",
        "        if not (os.path.isdir(artifacts_uri) or artifacts_uri.startswith(\"gs://\")):\n",
        "            raise ValueError(\"Provided artifact_uri is not a directory.\")\n",
        "\n",
        "        print(f\"Downloading checkpoints from {artifacts_uri}\")\n",
        "        prediction_utils.download_model_artifacts(artifacts_uri)\n",
        "\n",
        "        artifact_path = os.getcwd()  # Assuming model is downloaded to current working directory\n",
        "\n",
        "\n",
        "        print(f\"Loading checkpoints from {artifact_path}\")\n",
        "\n",
        "        self._model = timesfm.TimesFm(\n",
        "            context_len=self.CONTEXT_LEN,\n",
        "            horizon_len=self.HORIZON_LEN,\n",
        "            input_patch_len=self.INPUT_PATCH_LEN,\n",
        "            output_patch_len=self.OUTPUT_PATCH_LEN,\n",
        "            num_layers=self.NUM_LAYERS,\n",
        "            model_dims=self.MODEL_DIMS,\n",
        "            backend=self.BACKEND,\n",
        "        )\n",
        "\n",
        "        self._model.load_from_checkpoint(artifact_path, checkpoint_type=checkpoints.CheckpointType.FLAX)\n",
        "        print(f\"Loaded TimesFM model from {artifact_path}\")\n",
        "\n",
        "    def preprocess(self, request_dict: Dict[str, Dict]) -> Sequence[Any]:\n",
        "          \"\"\"Performs preprocessing.\n",
        "\n",
        "          By default, the server expects a request body consisting of a valid JSON\n",
        "          object. This will be parsed by the handler before it's evaluated by the\n",
        "          preprocess method.\n",
        "\n",
        "          Args:\n",
        "              request_dict: Parsed request body. We expect that the input consists of\n",
        "                  a list of time-series forecast contexts. Each context should be in\n",
        "                  a format convertible to JTensor by `jnp.array`.\n",
        "\n",
        "          Returns:\n",
        "              Time-series forecast contexts are passed as is from the input as a list.\n",
        "          \"\"\"\n",
        "\n",
        "          format = \"\"\"\n",
        "          {\n",
        "              \"instances\": [\n",
        "                  {\n",
        "                      \"inputs\": [\n",
        "                          [...],\n",
        "                          [...]\n",
        "                      ],\n",
        "                      \"freq\": [\n",
        "                          \"0/1/2\",\n",
        "                          \"0/1/2\"\n",
        "                      ]\n",
        "                  }\n",
        "              ]\n",
        "          }\n",
        "          \"\"\"\n",
        "\n",
        "\n",
        "          # Check for 'instances' key at the top level\n",
        "          if \"instances\" not in request_dict:\n",
        "              raise HTTPException(status_code=400, detail='Request must contain \"instances\" as a top-level key.')\n",
        "\n",
        "          result = request_dict[\"instances\"]\n",
        "          # Check if 'instances' is a sequence (list or tuple) and is not empty\n",
        "          if  isinstance(result, Sequence) and len(result) == 0:  # Simplified this condition\n",
        "              raise HTTPException(\n",
        "                  status_code=400,\n",
        "                  detail=f\"Invalid payload. Expected format is {format}. Received {type(result)}\"\n",
        "              )\n",
        "          print(\"Result is:\", result)\n",
        "\n",
        "          result = result[0]\n",
        "\n",
        "          print(\"Result[0] is:\", result)\n",
        "\n",
        "\n",
        "          if \"inputs\" in result:\n",
        "              inputs = result[\"inputs\"]  # Extract 'inputs'\n",
        "              print(\"inputs is:\", inputs)\n",
        "              # Check if 'inputs' is a list or tuple, and each element is also a list or tuple.\n",
        "              if not isinstance(inputs, Sequence) or not all(isinstance(x, Sequence) for x in inputs):\n",
        "                  raise HTTPException(\n",
        "                      status_code=400,\n",
        "                      detail=f\"Invalid datatype. Expected a list of time series forecast contexts. Received {type(inputs)}\"\n",
        "                  )\n",
        "          else:\n",
        "              raise HTTPException(\n",
        "                  status_code=400,\n",
        "                  detail=f\"Invalid payload. Expected format is {format} with keys 'inputs' and 'freq' (frequencies).\"\n",
        "                  f\"Received payload with type:{type(result)}\",\n",
        "              )\n",
        "          print(\"Result is:\", result)\n",
        "          return result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, instances: Dict[str, List]) -> Tuple[List, List]:\n",
        "        \"\"\"Performs time series forecasting using the TimesFM model.\n",
        "\n",
        "        Args:\n",
        "            instances: A dictionary with two keys:\n",
        "                - \"inputs\": List of time series forecast contexts. Each context should be convertible to a JAX NumPy array (jnp.array).\n",
        "                - \"freq\": (Optional) Frequencies of each forecast context with values 0 (high), 1 (medium), or 2 (low).\n",
        "\n",
        "        Returns:\n",
        "            A tuple containing two lists:\n",
        "                - point_forecast: Mean forecast of size (number of inputs, forecast horizon).\n",
        "                - quantile_forecast: Full forecast (mean + quantiles) of size (number of inputs, forecast horizon, 1 + number of quantiles).\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If the \"inputs\" key is missing in the input dictionary.\n",
        "        \"\"\"\n",
        "\n",
        "        # Extract inputs\n",
        "        inputs = instances[\"inputs\"]\n",
        "\n",
        "        \"\"\"\n",
        "        if inputs is None:\n",
        "            raise ValueError(\"Missing 'inputs' key in the request data.\")\n",
        "\n",
        "        # Convert inputs to JAX arrays for efficient computation\n",
        "        inputs = [jnp.array(ts_input) for ts_input in inputs]\n",
        "        \"\"\"\n",
        "\n",
        "        # Extract frequencies (if provided) or use default (None)\n",
        "        freq = None\n",
        "        if \"freq\" in instances:\n",
        "          freq = instances[\"freq\"]\n",
        "\n",
        "        # Generate forecasts using the TimesFM model\n",
        "        point_forecast, quantile_forecast = self._model.forecast(inputs, freq)\n",
        "        # Convert forecasts to standard Python lists for serialization\n",
        "        point_forecast = point_forecast.tolist()\n",
        "        quantile_forecast = quantile_forecast.tolist()\n",
        "\n",
        "        return point_forecast, quantile_forecast\n",
        "\n",
        "    def postprocess(self, forecasts: Tuple[List, List]) -> Dict[str, List[Dict[str, Union[int, float]]]]:\n",
        "        \"\"\"Translate the model output\n",
        "\n",
        "        Args:\n",
        "            forecasts: A tuple of List\n",
        "                - the mean forecast of size (# inputs, # forecast horizon),\n",
        "                - the full forecast (mean + quantiles) of size\n",
        "                    (#inputs, # forecast horizon, 1 + # quantiles).\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing the list of point forecasts and quantile forecasts\n",
        "            for each of the input time-series context.\n",
        "        \"\"\"\n",
        "        point_forecasts, quantile_forecasts = forecasts\n",
        "        predictions = [\n",
        "            dict(\n",
        "                point_forecast=points,\n",
        "                quantile_forecast=quantiles,\n",
        "            )\n",
        "            for (points, quantiles) in zip(point_forecasts, quantile_forecasts)\n",
        "        ]\n",
        "\n",
        "        print(\"Quantile forecasts:\", quantile_forecasts)\n",
        "\n",
        "        return {\"predictions\": predictions}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIMrEAGAZhmo",
        "outputId": "e29b803b-9e20-4a2c-e339-f52a747b8a62"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/timesfm_serving/predictor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/google-research/timesfm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s4JRwbtcgLn",
        "outputId": "c857da47-57ef-4879-e2df-c096352e1af2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'timesfm'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 121 (delta 55), reused 102 (delta 46), pack-reused 1\u001b[K\n",
            "Receiving objects: 100% (121/121), 547.21 KiB | 12.73 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $GCS_TIMESFM_CKPT_PATH\n",
        "print(\"HF Model:\", HF_TIMESFM_MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZtFTgUuCNfR",
        "outputId": "a39b55b0-e186-4760-99f5-8392cf811b48"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://firstargolisbucket/models/timesfm\n",
            "HF Model: google/timesfm-1.0-200m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Simple Unit test with Predictor\n",
        "\n",
        "# 4. Run simple unit test to ensure predictor works [Optional]\n",
        "from praxis.layers import transformers\n",
        "import sys\n",
        "\n",
        "import timesfm\n",
        "from src.timesfm_serving.predictor import TimesFMPredictor\n",
        "\n",
        "# define predictor\n",
        "predictor = TimesFMPredictor()\n",
        "\n",
        "# Load model checkpoint\n",
        "predictor.load(f\"{GCS_TIMESFM_CKPT_PATH}/checkpoints\")\n",
        "\n",
        "# create payload\n",
        "inputs = [list(np.linspace(0, 1, 100)), list(np.sin(np.linspace(0, 20, 200)))]\n",
        "payload = {\"instances\": [{\"inputs\": inputs}]}\n",
        "\n",
        "print(payload)"
      ],
      "metadata": {
        "id": "gT2kH7sVlhGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preprocess Payload, Predict & Generate output\n",
        "\n",
        "# preprocess, predict and post-process\n",
        "preprocessed_inputs = predictor.preprocess(payload)\n",
        "print(\"Preprocessed inputs:\", preprocessed_inputs)\n",
        "pt_forecast, quantil_forecast = predictor.predict(preprocessed_inputs)\n",
        "print(\"Predict output:\", pt_forecast, quantil_forecast)\n",
        "result = pt_forecast, quantil_forecast\n",
        "preprocessed_outputs = predictor.postprocess(result)\n",
        "print(preprocessed_outputs)\n"
      ],
      "metadata": {
        "id": "o_IL_vqPj0NJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $PATH_TO_THE_SOURCE_DIR/main.py\n",
        "import os\n",
        "\n",
        "import json\n",
        "import flask\n",
        "\n",
        "from predictor import TimesFMPredictor\n",
        "\n",
        "# Creation of the Flask app\n",
        "app = flask.Flask(__name__)\n",
        "\n",
        "# define predictor and Load model checkpoint\n",
        "predictor = TimesFMPredictor()\n",
        "\n",
        "predictor.load(os.environ['AIP_STORAGE_URI'])\n",
        "\n",
        "@app.route(os.environ['AIP_HEALTH_ROUTE'], methods=['GET'])\n",
        "def health() -> flask.Response:\n",
        "    return flask.Response(status=200)\n",
        "\n",
        "@app.route(os.environ['AIP_PREDICT_ROUTE'], methods=['GET', 'POST'])\n",
        "def predict() -> flask.Response:\n",
        "    try:\n",
        "        body = flask.request.get_json(silent=True, force=True)\n",
        "        preprocessed_inputs = predictor.preprocess(body)\n",
        "        outputs = predictor.predict(preprocessed_inputs)\n",
        "        postprocessed_outputs = predictor.postprocess(outputs)\n",
        "        return flask.Response(json.dumps(postprocessed_outputs), status=200, mimetype='application/json')\n",
        "\n",
        "        except Exception as e:  # pylint: disable=broad-except-caught\n",
        "            return flask.Response(json.dumps({'error': str(e)}), status=500, mimetype='application/json')\n",
        "\n",
        "        if __name__ == '__main__':\n",
        "            app.run(host='0.0.0.0', port=os.environ['AIP_HTTP_PORT'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjR2KiVjkzcK",
        "outputId": "f15c4bbc-9fa6-41c5-bdc3-3fbefa29a95d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/timesfm_serving/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Requirements.txt file in timesfm_serving\n",
        "%%writefile src/timesfm_serving/requirements.txt\n",
        "einshape\n",
        "paxml\n",
        "praxis\n",
        "jax\n",
        "numpy\n",
        "pandas\n",
        "utilsforecast\n",
        "fastapi\n",
        "docker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRwGHWS-Gi4b",
        "outputId": "8470c2bf-5137-4838-f9a7-dc7dd017ca8a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/timesfm_serving/requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 5: Build a Custom Container\n",
        "%%writefile src/Dockerfile\n",
        "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.10\n",
        "\n",
        "# install dependencies\n",
        "COPY timesfm_serving/requirements.txt /app/\n",
        "\n",
        "RUN pip install -r /app/requirements.txt\n",
        "\n",
        "# copy app files\n",
        "COPY timesfm_serving/ /app\n",
        "\n",
        "# download timesfm inference modules\n",
        "RUN git clone https://github.com/google-research/timesfm.git\n",
        "\n",
        "RUN rm timesfm/__init__.py\n",
        "RUN sed -i 's#^from src#from .#g' timesfm/src/timesfm.py\n",
        "\n",
        "# run inference\n",
        "CMD [\"python\", \"main.py\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttGsDnm_sMIu",
        "outputId": "b912a011-dbe8-432a-ecfc-24346401e690"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/Dockerfile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $TIMESFM_IMAGE_URI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcfDV86hGEAe",
        "outputId": "cc154be1-5d90-4c6b-d40c-187b66cb0fde"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd src\n",
        "!gcloud builds submit --tag=$TIMESFM_IMAGE_URI\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-Q1drSsDj-n",
        "outputId": "1eee7e16-9727-4468-ae93-5f7e0e701b74"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/src\n",
            "Creating temporary archive of 7 file(s) totalling 16.4 KiB before compression.\n",
            "Uploading tarball of [.] to [gs://argolis-project-340214_cloudbuild/source/1716513794.648469-5b9660f810954df8aa352c2e483d6291.tgz]\n",
            "Created [https://cloudbuild.googleapis.com/v1/projects/argolis-project-340214/locations/global/builds/0e3254ec-7ca6-4c6c-9d4b-e6eb1727cb63].\n",
            "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/0e3254ec-7ca6-4c6c-9d4b-e6eb1727cb63?project=742458474659 ].\n",
            "Waiting for build to complete. Polling interval: 1 second(s).\n",
            " REMOTE BUILD OUTPUT\n",
            "starting build \"0e3254ec-7ca6-4c6c-9d4b-e6eb1727cb63\"\n",
            "\n",
            "FETCHSOURCE\n",
            "Fetching storage object: gs://argolis-project-340214_cloudbuild/source/1716513794.648469-5b9660f810954df8aa352c2e483d6291.tgz#1716513795062969\n",
            "Copying gs://argolis-project-340214_cloudbuild/source/1716513794.648469-5b9660f810954df8aa352c2e483d6291.tgz#1716513795062969...\n",
            "/ [1 files][  6.0 KiB/  6.0 KiB]                                                \n",
            "Operation completed over 1 objects/6.0 KiB.\n",
            "BUILD\n",
            "Already have image (with digest): gcr.io/cloud-builders/docker\n",
            "Sending build context to Docker daemon  24.06kB\n",
            "Step 1/8 : FROM tiangolo/uvicorn-gunicorn-fastapi:python3.10\n",
            "python3.10: Pulling from tiangolo/uvicorn-gunicorn-fastapi\n",
            "c6cf28de8a06: Already exists\n",
            "891494355808: Already exists\n",
            "6582c62583ef: Already exists\n",
            "bf2c3e352f3d: Already exists\n",
            "a99509a32390: Already exists\n",
            "946285778af4: Pulling fs layer\n",
            "b2ab5d29389b: Pulling fs layer\n",
            "d76e704b1be9: Pulling fs layer\n",
            "32b14c58fcfc: Pulling fs layer\n",
            "49c9ff2efd6b: Pulling fs layer\n",
            "5119e73f1536: Pulling fs layer\n",
            "b82c8e4a85c6: Pulling fs layer\n",
            "30c0e033ca4b: Pulling fs layer\n",
            "88ccd20b36d3: Pulling fs layer\n",
            "abf00b58c1b0: Pulling fs layer\n",
            "8e6b754449a4: Pulling fs layer\n",
            "4f4fb700ef54: Pulling fs layer\n",
            "12eeb765d0fa: Pulling fs layer\n",
            "9bab74df5c6b: Pulling fs layer\n",
            "e64e5e7eb223: Pulling fs layer\n",
            "32b14c58fcfc: Waiting\n",
            "49c9ff2efd6b: Waiting\n",
            "5119e73f1536: Waiting\n",
            "b82c8e4a85c6: Waiting\n",
            "30c0e033ca4b: Waiting\n",
            "88ccd20b36d3: Waiting\n",
            "abf00b58c1b0: Waiting\n",
            "8e6b754449a4: Waiting\n",
            "4f4fb700ef54: Waiting\n",
            "12eeb765d0fa: Waiting\n",
            "9bab74df5c6b: Waiting\n",
            "e64e5e7eb223: Waiting\n",
            "b2ab5d29389b: Verifying Checksum\n",
            "b2ab5d29389b: Download complete\n",
            "d76e704b1be9: Verifying Checksum\n",
            "d76e704b1be9: Download complete\n",
            "946285778af4: Verifying Checksum\n",
            "946285778af4: Download complete\n",
            "32b14c58fcfc: Verifying Checksum\n",
            "32b14c58fcfc: Download complete\n",
            "5119e73f1536: Verifying Checksum\n",
            "5119e73f1536: Download complete\n",
            "49c9ff2efd6b: Verifying Checksum\n",
            "49c9ff2efd6b: Download complete\n",
            "b82c8e4a85c6: Verifying Checksum\n",
            "b82c8e4a85c6: Download complete\n",
            "30c0e033ca4b: Verifying Checksum\n",
            "30c0e033ca4b: Download complete\n",
            "946285778af4: Pull complete\n",
            "b2ab5d29389b: Pull complete\n",
            "abf00b58c1b0: Verifying Checksum\n",
            "abf00b58c1b0: Download complete\n",
            "88ccd20b36d3: Verifying Checksum\n",
            "88ccd20b36d3: Download complete\n",
            "8e6b754449a4: Verifying Checksum\n",
            "8e6b754449a4: Download complete\n",
            "d76e704b1be9: Pull complete\n",
            "4f4fb700ef54: Verifying Checksum\n",
            "4f4fb700ef54: Download complete\n",
            "32b14c58fcfc: Pull complete\n",
            "12eeb765d0fa: Verifying Checksum\n",
            "12eeb765d0fa: Download complete\n",
            "e64e5e7eb223: Verifying Checksum\n",
            "e64e5e7eb223: Download complete\n",
            "9bab74df5c6b: Verifying Checksum\n",
            "9bab74df5c6b: Download complete\n",
            "49c9ff2efd6b: Pull complete\n",
            "5119e73f1536: Pull complete\n",
            "b82c8e4a85c6: Pull complete\n",
            "30c0e033ca4b: Pull complete\n",
            "88ccd20b36d3: Pull complete\n",
            "abf00b58c1b0: Pull complete\n",
            "8e6b754449a4: Pull complete\n",
            "4f4fb700ef54: Pull complete\n",
            "12eeb765d0fa: Pull complete\n",
            "9bab74df5c6b: Pull complete\n",
            "e64e5e7eb223: Pull complete\n",
            "Digest: sha256:378a01a6d466a79271aacb5b824f4e6915817698f66f263dc64c9e39f0995972\n",
            "Status: Downloaded newer image for tiangolo/uvicorn-gunicorn-fastapi:python3.10\n",
            " ---> 8483dc505071\n",
            "Step 2/8 : COPY timesfm_serving/requirements.txt /app/\n",
            " ---> 5fe40d2254a0\n",
            "Step 3/8 : RUN pip install -r /app/requirements.txt\n",
            " ---> Running in f67b582310b3\n",
            "Collecting einshape\n",
            "  Downloading einshape-1.0-py3-none-any.whl (21 kB)\n",
            "Collecting paxml\n",
            "  Downloading paxml-1.4.0-py3-none-any.whl (440 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 440.2/440.2 kB 12.5 MB/s eta 0:00:00\n",
            "Collecting praxis\n",
            "  Downloading praxis-1.4.0-py3-none-any.whl (772 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 772.5/772.5 kB 31.6 MB/s eta 0:00:00\n",
            "Collecting jax\n",
            "  Downloading jax-0.4.28-py3-none-any.whl (1.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 49.8 MB/s eta 0:00:00\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 64.1 MB/s eta 0:00:00\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.0/13.0 MB 76.8 MB/s eta 0:00:00\n",
            "Collecting utilsforecast\n",
            "  Downloading utilsforecast-0.1.10-py3-none-any.whl (40 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.5/40.5 kB 6.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/site-packages (from -r /app/requirements.txt (line 8)) (0.88.0)\n",
            "Collecting docker\n",
            "  Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.8/147.8 kB 21.1 MB/s eta 0:00:00\n",
            "Collecting absl-py\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.7/133.7 kB 21.8 MB/s eta 0:00:00\n",
            "Collecting tensorflow-datasets==4.8.3\n",
            "  Downloading tensorflow_datasets-4.8.3-py3-none-any.whl (5.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 80.9 MB/s eta 0:00:00\n",
            "Collecting lingvo==0.12.7\n",
            "  Downloading lingvo-0.12.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.0/18.0 MB 62.4 MB/s eta 0:00:00\n",
            "Collecting seqio-nightly==0.0.17.dev20231010\n",
            "  Downloading seqio_nightly-0.0.17.dev20231010-py3-none-any.whl (353 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 353.1/353.1 kB 42.3 MB/s eta 0:00:00\n",
            "Collecting orbax-checkpoint==0.5.9\n",
            "  Downloading orbax_checkpoint-0.5.9-py3-none-any.whl (168 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.0/168.0 kB 24.1 MB/s eta 0:00:00\n",
            "Collecting t5==0.9.4\n",
            "  Downloading t5-0.9.4-py2.py3-none-any.whl (164 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 164.5/164.5 kB 22.5 MB/s eta 0:00:00\n",
            "Collecting pyglove==0.4.4\n",
            "  Downloading pyglove-0.4.4-py3-none-any.whl (577 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 577.8/577.8 kB 48.9 MB/s eta 0:00:00\n",
            "Collecting absl-py\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 20.6 MB/s eta 0:00:00\n",
            "Collecting flax==0.8.2\n",
            "  Downloading flax-0.8.2-py3-none-any.whl (686 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 686.8/686.8 kB 52.9 MB/s eta 0:00:00\n",
            "Collecting graphviz==0.20.1\n",
            "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 6.8 MB/s eta 0:00:00\n",
            "Collecting tensorstore==0.1.55\n",
            "  Downloading tensorstore-0.1.55-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.3/14.3 MB 72.8 MB/s eta 0:00:00\n",
            "Collecting jax\n",
            "  Downloading jax-0.4.26-py3-none-any.whl (1.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 72.1 MB/s eta 0:00:00\n",
            "Collecting protobuf==3.19.6\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 69.3 MB/s eta 0:00:00\n",
            "Collecting tensorflow-text~=2.9.0\n",
            "  Downloading tensorflow_text-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.6/4.6 MB 76.7 MB/s eta 0:00:00\n",
            "Collecting tfds-nightly==4.8.3.dev202303280045\n",
            "  Downloading tfds_nightly-4.8.3.dev202303280045-py3-none-any.whl (5.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 80.4 MB/s eta 0:00:00\n",
            "Collecting etils==1.7.0\n",
            "  Downloading etils-1.7.0-py3-none-any.whl (152 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.4/152.4 kB 22.9 MB/s eta 0:00:00\n",
            "Collecting tensorflow-metadata==1.12.0\n",
            "  Downloading tensorflow_metadata-1.12.0-py3-none-any.whl (52 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.3/52.3 kB 3.7 MB/s eta 0:00:00\n",
            "Collecting tensorflow~=2.9.2\n",
            "  Downloading tensorflow-2.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 511.8/511.8 MB 2.7 MB/s eta 0:00:00\n",
            "Collecting clu==0.0.11\n",
            "  Downloading clu-0.0.11-py3-none-any.whl (101 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.4/101.4 kB 16.1 MB/s eta 0:00:00\n",
            "Collecting sentencepiece==0.1.99\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 73.0 MB/s eta 0:00:00\n",
            "Collecting jaxtyping==0.2.28\n",
            "  Downloading jaxtyping-0.2.28-py3-none-any.whl (40 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.7/40.7 kB 6.8 MB/s eta 0:00:00\n",
            "Collecting einops==0.7.0\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.6/44.6 kB 7.6 MB/s eta 0:00:00\n",
            "Collecting opt-einsum==3.3.0\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 11.5 MB/s eta 0:00:00\n",
            "Collecting chex>=0.1.85\n",
            "  Downloading chex-0.1.86-py3-none-any.whl (98 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.2/98.2 kB 15.1 MB/s eta 0:00:00\n",
            "Collecting jax-bitempered-loss==0.0.2\n",
            "  Downloading jax_bitempered_loss-0.0.2-py3-none-any.whl (12 kB)\n",
            "Collecting optax==0.2.2\n",
            "  Downloading optax-0.2.2-py3-none-any.whl (223 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 223.7/223.7 kB 31.0 MB/s eta 0:00:00\n",
            "Collecting typeguard==2.13.3\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting optax-shampoo==0.0.6\n",
            "  Downloading optax_shampoo-0.0.6-py3-none-any.whl (32 kB)\n",
            "Collecting fiddle==0.3.0\n",
            "  Downloading fiddle-0.3.0-py3-none-any.whl (419 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 419.8/419.8 kB 42.8 MB/s eta 0:00:00\n",
            "Collecting scipy>=1.9\n",
            "  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.6/38.6 MB 41.0 MB/s eta 0:00:00\n",
            "Collecting ml-dtypes>=0.2.0\n",
            "  Downloading ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 78.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from clu==0.0.11->paxml->-r /app/requirements.txt (line 2)) (24.0)\n",
            "Collecting ml-collections\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.9/77.9 kB 13.5 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from clu==0.0.11->paxml->-r /app/requirements.txt (line 2)) (4.11.0)\n",
            "Collecting wrapt\n",
            "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.3/80.3 kB 12.8 MB/s eta 0:00:00\n",
            "Collecting jaxlib\n",
            "  Downloading jaxlib-0.4.28-cp310-cp310-manylinux2014_x86_64.whl (77.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.5/77.5 MB 21.6 MB/s eta 0:00:00\n",
            "Collecting libcst\n",
            "  Downloading libcst-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 82.4 MB/s eta 0:00:00\n",
            "Collecting rich>=11.1\n",
            "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 240.7/240.7 kB 33.9 MB/s eta 0:00:00\n",
            "Collecting msgpack\n",
            "  Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 385.1/385.1 kB 41.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/site-packages (from flax==0.8.2->paxml->-r /app/requirements.txt (line 2)) (6.0.1)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 89.1 MB/s eta 0:00:00\n",
            "Collecting attrs\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.8/60.8 kB 9.7 MB/s eta 0:00:00\n",
            "Collecting Pillow\n",
            "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 90.6 MB/s eta 0:00:00\n",
            "Collecting model-pruning-google-research\n",
            "  Downloading model_pruning_google_research-0.0.5-py3-none-any.whl (52 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.6/52.6 kB 8.9 MB/s eta 0:00:00\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 36.5 MB/s eta 0:00:00\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.3/13.3 MB 80.2 MB/s eta 0:00:00\n",
            "Collecting graph-compression-google-research\n",
            "  Downloading graph_compression_google_research-0.0.4-py3-none-any.whl (90 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.0/90.0 kB 13.9 MB/s eta 0:00:00\n",
            "Collecting tensorflow-hub\n",
            "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.29.4-py3-none-any.whl (117 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.1/117.1 kB 18.6 MB/s eta 0:00:00\n",
            "Collecting jupyter-http-over-ws\n",
            "  Downloading jupyter_http_over_ws-0.0.8-py2.py3-none-any.whl (18 kB)\n",
            "Collecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting nest_asyncio\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Collecting docstring-parser>=0.12\n",
            "  Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "Collecting editdistance\n",
            "  Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 401.8/401.8 kB 45.1 MB/s eta 0:00:00\n",
            "Collecting gin-config\n",
            "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.3/61.3 kB 10.4 MB/s eta 0:00:00\n",
            "Collecting six>=1.14\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 67.5 MB/s eta 0:00:00\n",
            "Collecting babel\n",
            "  Downloading Babel-2.15.0-py3-none-any.whl (9.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.6/9.6 MB 89.9 MB/s eta 0:00:00\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 385.2/385.2 kB 40.9 MB/s eta 0:00:00\n",
            "Collecting rouge-score>=0.1.2\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 106.7/106.7 kB 18.9 MB/s eta 0:00:00\n",
            "Collecting transformers>=2.7.0\n",
            "  Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.1/9.1 MB 87.6 MB/s eta 0:00:00\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting promise\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 kB 14.1 MB/s eta 0:00:00\n",
            "Collecting requests>=2.19.0\n",
            "  Downloading requests-2.32.2-py3-none-any.whl (63 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.9/63.9 kB 11.4 MB/s eta 0:00:00\n",
            "Collecting termcolor\n",
            "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.8.3->paxml->-r /app/requirements.txt (line 2)) (8.1.7)\n",
            "Collecting psutil\n",
            "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 288.2/288.2 kB 27.7 MB/s eta 0:00:00\n",
            "Collecting dm-tree\n",
            "  Downloading dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.8/152.8 kB 21.3 MB/s eta 0:00:00\n",
            "Collecting googleapis-common-protos<2,>=1.52.0\n",
            "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.1/229.1 kB 26.7 MB/s eta 0:00:00\n",
            "Collecting array-record\n",
            "  Downloading array_record-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 80.6 MB/s eta 0:00:00\n",
            "Collecting tzdata>=2022.7\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 345.4/345.4 kB 39.4 MB/s eta 0:00:00\n",
            "Collecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 30.2 MB/s eta 0:00:00\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 505.5/505.5 kB 45.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: starlette==0.22.0 in /usr/local/lib/python3.10/site-packages (from fastapi->-r /app/requirements.txt (line 8)) (0.22.0)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.10/site-packages (from fastapi->-r /app/requirements.txt (line 8)) (1.10.15)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from starlette==0.22.0->fastapi->-r /app/requirements.txt (line 8)) (4.3.0)\n",
            "Collecting urllib3>=1.26.0\n",
            "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.1/121.1 kB 19.6 MB/s eta 0:00:00\n",
            "Collecting toolz>=0.9.0\n",
            "  Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.1/56.1 kB 9.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets==4.8.3->paxml->-r /app/requirements.txt (line 2)) (2024.2.2)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.1/142.1 kB 22.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets==4.8.3->paxml->-r /app/requirements.txt (line 2)) (3.7)\n",
            "Collecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 90.6 MB/s eta 0:00:00\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 91.5 MB/s eta 0:00:00\n",
            "Collecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 87.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from tensorflow~=2.9.2->paxml->-r /app/requirements.txt (line 2)) (65.5.1)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting libclang>=13.0.0\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.5/24.5 MB 56.4 MB/s eta 0:00:00\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 438.7/438.7 kB 45.0 MB/s eta 0:00:00\n",
            "Collecting h5py>=2.9.0\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 90.5 MB/s eta 0:00:00\n",
            "Collecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 10.2 MB/s eta 0:00:00\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.6/42.6 kB 7.4 MB/s eta 0:00:00\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 52.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi->-r /app/requirements.txt (line 8)) (1.2.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi->-r /app/requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow~=2.9.2->paxml->-r /app/requirements.txt (line 2)) (0.43.0)\n",
            "Collecting zipp\n",
            "  Downloading zipp-3.18.2-py3-none-any.whl (8.3 kB)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 316.1/316.1 kB 37.5 MB/s eta 0:00:00\n",
            "Collecting importlib_resources\n",
            "  Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
            "Collecting future\n",
            "  Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 491.3/491.3 kB 44.4 MB/s eta 0:00:00\n",
            "Collecting pygments<3.0.0,>=2.13.0\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 66.5 MB/s eta 0:00:00\n",
            "Collecting markdown-it-py>=2.2.0\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.5/87.5 kB 15.6 MB/s eta 0:00:00\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 189.2/189.2 kB 27.9 MB/s eta 0:00:00\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 54.6 MB/s eta 0:00:00\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.4/105.4 kB 16.6 MB/s eta 0:00:00\n",
            "Collecting werkzeug>=1.0.1\n",
            "  Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 227.3/227.3 kB 31.4 MB/s eta 0:00:00\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 89.3 MB/s eta 0:00:00\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tf-keras>=2.14.1\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 77.0 MB/s eta 0:00:00\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.23.0\n",
            "  Downloading huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 401.3/401.3 kB 43.0 MB/s eta 0:00:00\n",
            "Collecting tokenizers<0.20,>=0.19\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 72.2 MB/s eta 0:00:00\n",
            "Collecting safetensors>=0.4.1\n",
            "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 73.5 MB/s eta 0:00:00\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 775.1/775.1 kB 56.9 MB/s eta 0:00:00\n",
            "Collecting pyzmq>=24\n",
            "  Downloading pyzmq-26.0.3-cp310-cp310-manylinux_2_28_x86_64.whl (919 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 919.8/919.8 kB 59.5 MB/s eta 0:00:00\n",
            "Collecting jupyter-client>=6.1.12\n",
            "  Downloading jupyter_client-8.6.2-py3-none-any.whl (105 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.9/105.9 kB 16.9 MB/s eta 0:00:00\n",
            "Collecting ipython>=7.23.1\n",
            "  Downloading ipython-8.24.0-py3-none-any.whl (816 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 816.5/816.5 kB 53.7 MB/s eta 0:00:00\n",
            "Collecting matplotlib-inline>=0.1\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Collecting debugpy>=1.6.5\n",
            "  Downloading debugpy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 85.2 MB/s eta 0:00:00\n",
            "Collecting jupyter-core!=5.0.*,>=4.12\n",
            "  Downloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
            "Collecting traitlets>=5.4.0\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.4/85.4 kB 13.3 MB/s eta 0:00:00\n",
            "Collecting comm>=0.1.1\n",
            "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Collecting tornado>=6.1\n",
            "  Downloading tornado-6.4-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 435.4/435.4 kB 44.4 MB/s eta 0:00:00\n",
            "Collecting notebook\n",
            "  Downloading notebook-7.2.0-py3-none-any.whl (5.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.0/5.0 MB 86.4 MB/s eta 0:00:00\n",
            "Collecting qtconsole\n",
            "  Downloading qtconsole-5.5.2-py3-none-any.whl (123 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.4/123.4 kB 19.9 MB/s eta 0:00:00\n",
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.4/139.4 kB 18.5 MB/s eta 0:00:00\n",
            "Collecting jupyter-console\n",
            "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
            "Collecting nbconvert\n",
            "  Downloading nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 257.4/257.4 kB 34.9 MB/s eta 0:00:00\n",
            "Collecting kiwisolver>=1.3.1\n",
            "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 76.1 MB/s eta 0:00:00\n",
            "Collecting pyparsing>=2.3.1\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.2/103.2 kB 16.1 MB/s eta 0:00:00\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.51.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.6/4.6 MB 20.2 MB/s eta 0:00:00\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 305.2/305.2 kB 34.4 MB/s eta 0:00:00\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting contextlib2\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.8/301.8 kB 37.3 MB/s eta 0:00:00\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Collecting tabulate>=0.8.9\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting lxml\n",
            "  Downloading lxml-5.2.2-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.0/5.0 MB 90.2 MB/s eta 0:00:00\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting threadpoolctl>=3.1.0\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 51.4 MB/s eta 0:00:00\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.2/181.2 kB 27.7 MB/s eta 0:00:00\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting prompt-toolkit<3.1.0,>=3.0.41\n",
            "  Downloading prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 386.1/386.1 kB 41.1 MB/s eta 0:00:00\n",
            "Collecting pexpect>4.3\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.8/63.8 kB 9.9 MB/s eta 0:00:00\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 75.8 MB/s eta 0:00:00\n",
            "Collecting stack-data\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Collecting platformdirs>=2.5\n",
            "  Downloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting notebook-shim<0.3,>=0.2\n",
            "  Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
            "Collecting jupyterlab<4.3,>=4.2.0\n",
            "  Downloading jupyterlab-4.2.1-py3-none-any.whl (11.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 84.7 MB/s eta 0:00:00\n",
            "Collecting jupyter-server<3,>=2.4.0\n",
            "  Downloading jupyter_server-2.14.0-py3-none-any.whl (383 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 383.3/383.3 kB 41.2 MB/s eta 0:00:00\n",
            "Collecting jupyterlab-server<3,>=2.27.1\n",
            "  Downloading jupyterlab_server-2.27.2-py3-none-any.whl (59 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.4/59.4 kB 9.6 MB/s eta 0:00:00\n",
            "Collecting tf-keras>=2.14.1\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 76.1 MB/s eta 0:00:00\n",
            "  Downloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 78.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml->-r /app/requirements.txt (line 2)) (2.1.5)\n",
            "Collecting widgetsnbextension~=4.0.10\n",
            "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 81.6 MB/s eta 0:00:00\n",
            "Collecting jupyterlab-widgets~=3.0.10\n",
            "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 215.0/215.0 kB 30.0 MB/s eta 0:00:00\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.9/147.9 kB 22.8 MB/s eta 0:00:00\n",
            "Collecting bleach!=5.0.0\n",
            "  Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 162.8/162.8 kB 25.5 MB/s eta 0:00:00\n",
            "Collecting nbformat>=5.7\n",
            "  Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 12.1 MB/s eta 0:00:00\n",
            "Collecting pandocfilters>=1.4.1\n",
            "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting jupyterlab-pygments\n",
            "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
            "Collecting tinycss2\n",
            "  Downloading tinycss2-1.3.0-py3-none-any.whl (22 kB)\n",
            "Collecting defusedxml\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Collecting mistune<4,>=2.0.3\n",
            "  Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.0/48.0 kB 8.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/site-packages (from nbconvert->jupyter->lingvo==0.12.7->paxml->-r /app/requirements.txt (line 2)) (3.1.4)\n",
            "Collecting nbclient>=0.5.0\n",
            "  Downloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
            "Collecting qtpy>=2.4.0\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.5/93.5 kB 15.2 MB/s eta 0:00:00\n",
            "Collecting webencodings\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting parso<0.9.0,>=0.8.3\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.7/103.7 kB 17.1 MB/s eta 0:00:00\n",
            "Collecting jupyter-events>=0.9.0\n",
            "  Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
            "Collecting overrides>=5.0\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Collecting terminado>=0.8.3\n",
            "  Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Collecting websocket-client>=1.7\n",
            "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 10.1 MB/s eta 0:00:00\n",
            "Collecting argon2-cffi>=21.1\n",
            "  Downloading argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
            "Collecting prometheus-client>=0.9\n",
            "  Downloading prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 6.7 MB/s eta 0:00:00\n",
            "Collecting send2trash>=1.8.2\n",
            "  Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
            "Collecting async-lru>=1.0.0\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Collecting jupyter-lsp>=2.0.0\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 69.1/69.1 kB 9.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.10/site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter->lingvo==0.12.7->paxml->-r /app/requirements.txt (line 2)) (0.27.0)\n",
            "Collecting tomli>=1.2.2\n",
            "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting json5>=0.9.0\n",
            "  Downloading json5-0.9.25-py3-none-any.whl (30 kB)\n",
            "Collecting jsonschema>=4.18.0\n",
            "  Downloading jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.3/88.3 kB 14.6 MB/s eta 0:00:00\n",
            "Collecting fastjsonschema>=2.15\n",
            "  Downloading fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
            "Collecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6\n",
            "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.3/85.3 kB 14.9 MB/s eta 0:00:00\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 25.0 MB/s eta 0:00:00\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
            "Collecting asttokens>=2.1.0\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting executing>=1.2.0\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting argon2-cffi-bindings\n",
            "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.2/86.2 kB 13.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter->lingvo==0.12.7->paxml->-r /app/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter->lingvo==0.12.7->paxml->-r /app/requirements.txt (line 2)) (0.14.0)\n",
            "Collecting rpds-py>=0.7.1\n",
            "  Downloading rpds_py-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 67.5 MB/s eta 0:00:00\n",
            "Collecting jsonschema-specifications>=2023.03.6\n",
            "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
            "Collecting referencing>=0.28.4\n",
            "  Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
            "Collecting rfc3986-validator>=0.1.1\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting python-json-logger>=2.0.4\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Collecting rfc3339-validator\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting fqdn\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting jsonpointer>1.13\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting isoduration\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting webcolors>=1.11\n",
            "  Downloading webcolors-1.13-py3-none-any.whl (14 kB)\n",
            "Collecting uri-template\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Collecting cffi>=1.0.1\n",
            "  Downloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 443.9/443.9 kB 46.1 MB/s eta 0:00:00\n",
            "Collecting pycparser\n",
            "  Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.6/117.6 kB 16.5 MB/s eta 0:00:00\n",
            "Collecting arrow>=0.15.0\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.4/66.4 kB 10.7 MB/s eta 0:00:00\n",
            "Collecting types-python-dateutil>=2.8.10\n",
            "  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\n",
            "Building wheels for collected packages: rouge-score, ml-collections, promise\n",
            "  Building wheel for rouge-score (setup.py): started\n",
            "  Building wheel for rouge-score (setup.py): finished with status 'done'\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=5e39af5dfa8ceee2d569739cfee0161cabed44bf3c5a04d2f71b12a8be33c0b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for ml-collections (setup.py): started\n",
            "  Building wheel for ml-collections (setup.py): finished with status 'done'\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=0ffd90828dbbe6af3b48fe989d9eb84cd05a09b254b65f9bd6b027289b636996\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
            "  Building wheel for promise (setup.py): started\n",
            "  Building wheel for promise (setup.py): finished with status 'done'\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21483 sha256=a7c8321da60755567b6e2ebfa417e8822cd650694407efdff132a828d1c35b27\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/4e/28/3ed0e1c8a752867445bab994d2340724928aa3ab059c57c8db\n",
            "Successfully built rouge-score ml-collections promise\n",
            "Installing collected packages: webencodings, wcwidth, tensorboard-plugin-wit, sentencepiece, pytz, pure-eval, ptyprocess, mpmath, libclang, keras, gin-config, flatbuffers, fastjsonschema, dm-tree, zipp, wrapt, widgetsnbextension, werkzeug, websocket-client, webcolors, urllib3, uri-template, tzdata, types-python-dateutil, typeguard, traitlets, tqdm, tornado, toolz, tomli, toml, tinycss2, threadpoolctl, tf-keras, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, tabulate, sympy, soupsieve, six, send2trash, safetensors, rpds-py, rfc3986-validator, regex, qtpy, pyzmq, python-json-logger, pyparsing, pygments, pycparser, pyasn1, psutil, protobuf, prompt-toolkit, prometheus-client, portalocker, platformdirs, Pillow, pexpect, parso, pandocfilters, overrides, optax-shampoo, oauthlib, numpy, nest_asyncio, msgpack, model-pruning-google-research, mistune, mdurl, markdown, lxml, libcst, kiwisolver, jupyterlab-widgets, jupyterlab-pygments, jsonpointer, json5, joblib, jax-bitempered-loss, importlib_resources, immutabledict, grpcio, graphviz, graph-compression-google-research, gast, future, fsspec, fqdn, fonttools, filelock, executing, etils, einops, editdistance, docstring-parser, defusedxml, decorator, debugpy, cycler, contextlib2, colorama, charset-normalizer, cachetools, babel, attrs, async-lru, absl-py, terminado, tensorflow-hub, scipy, sacrebleu, rsa, rfc3339-validator, requests, referencing, python-dateutil, pyglove, pyasn1-modules, promise, opt-einsum, nltk, ml-dtypes, ml-collections, mesh-tensorflow, matplotlib-inline, markdown-it-py, keras-preprocessing, jupyter-core, jedi, jaxtyping, h5py, googleapis-common-protos, google-pasta, fiddle, einshape, contourpy, comm, cffi, bleach, beautifulsoup4, astunparse, asttokens, tensorstore, tensorflow-metadata, stack-data, scikit-learn, rouge-score, rich, requests-oauthlib, pandas, matplotlib, jupyter-server-terminals, jupyter-client, jsonschema-specifications, jaxlib, jax, huggingface-hub, google-auth, docker, arrow, argon2-cffi-bindings, utilsforecast, tokenizers, tensorflow-datasets, orbax-checkpoint, jsonschema, isoduration, ipython, google-auth-oauthlib, chex, array-record, argon2-cffi, transformers, tfds-nightly, tensorboard, optax, nbformat, ipywidgets, ipykernel, tensorflow, qtconsole, nbclient, jupyter-events, jupyter-console, flax, tensorflow-text, nbconvert, clu, seqio-nightly, jupyter-server, t5, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter-http-over-ws, jupyter, lingvo, praxis, paxml\n",
            "Successfully installed Pillow-10.3.0 absl-py-1.4.0 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 array-record-0.5.1 arrow-1.3.0 asttokens-2.4.1 astunparse-1.6.3 async-lru-2.0.4 attrs-23.2.0 babel-2.15.0 beautifulsoup4-4.12.3 bleach-6.1.0 cachetools-5.3.3 cffi-1.16.0 charset-normalizer-3.3.2 chex-0.1.86 clu-0.0.11 colorama-0.4.6 comm-0.2.2 contextlib2-21.6.0 contourpy-1.2.1 cycler-0.12.1 debugpy-1.8.1 decorator-5.1.1 defusedxml-0.7.1 dm-tree-0.1.8 docker-7.1.0 docstring-parser-0.16 editdistance-0.8.1 einops-0.7.0 einshape-1.0 etils-1.7.0 executing-2.0.1 fastjsonschema-2.19.1 fiddle-0.3.0 filelock-3.14.0 flatbuffers-1.12 flax-0.8.2 fonttools-4.51.0 fqdn-1.5.1 fsspec-2024.5.0 future-1.0.0 gast-0.4.0 gin-config-0.5.0 google-auth-2.29.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.63.0 graph-compression-google-research-0.0.4 graphviz-0.20.1 grpcio-1.64.0 h5py-3.11.0 huggingface-hub-0.23.1 immutabledict-4.2.0 importlib_resources-6.4.0 ipykernel-6.29.4 ipython-8.24.0 ipywidgets-8.1.2 isoduration-20.11.0 jax-0.4.26 jax-bitempered-loss-0.0.2 jaxlib-0.4.28 jaxtyping-0.2.28 jedi-0.19.1 joblib-1.4.2 json5-0.9.25 jsonpointer-2.4 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 jupyter-1.0.0 jupyter-client-8.6.2 jupyter-console-6.6.3 jupyter-core-5.7.2 jupyter-events-0.10.0 jupyter-http-over-ws-0.0.8 jupyter-lsp-2.2.5 jupyter-server-2.14.0 jupyter-server-terminals-0.5.3 jupyterlab-4.2.1 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.2 jupyterlab-widgets-3.0.10 keras-2.9.0 keras-preprocessing-1.1.2 kiwisolver-1.4.5 libclang-18.1.1 libcst-1.4.0 lingvo-0.12.7 lxml-5.2.2 markdown-3.6 markdown-it-py-3.0.0 matplotlib-3.9.0 matplotlib-inline-0.1.7 mdurl-0.1.2 mesh-tensorflow-0.1.21 mistune-3.0.2 ml-collections-0.1.1 ml-dtypes-0.4.0 model-pruning-google-research-0.0.5 mpmath-1.3.0 msgpack-1.0.8 nbclient-0.10.0 nbconvert-7.16.4 nbformat-5.10.4 nest_asyncio-1.6.0 nltk-3.8.1 notebook-7.2.0 notebook-shim-0.2.4 numpy-1.26.4 oauthlib-3.2.2 opt-einsum-3.3.0 optax-0.2.2 optax-shampoo-0.0.6 orbax-checkpoint-0.5.9 overrides-7.7.0 pandas-2.2.2 pandocfilters-1.5.1 parso-0.8.4 paxml-1.4.0 pexpect-4.9.0 platformdirs-4.2.2 portalocker-2.8.2 praxis-1.4.0 prometheus-client-0.20.0 promise-2.3 prompt-toolkit-3.0.43 protobuf-3.19.6 psutil-5.9.8 ptyprocess-0.7.0 pure-eval-0.2.2 pyasn1-0.6.0 pyasn1-modules-0.4.0 pycparser-2.22 pyglove-0.4.4 pygments-2.18.0 pyparsing-3.1.2 python-dateutil-2.9.0.post0 python-json-logger-2.0.7 pytz-2024.1 pyzmq-26.0.3 qtconsole-5.5.2 qtpy-2.4.1 referencing-0.35.1 regex-2024.5.15 requests-2.32.2 requests-oauthlib-2.0.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rich-13.7.1 rouge-score-0.1.2 rpds-py-0.18.1 rsa-4.9 sacrebleu-2.4.2 safetensors-0.4.3 scikit-learn-1.5.0 scipy-1.13.1 send2trash-1.8.3 sentencepiece-0.1.99 seqio-nightly-0.0.17.dev20231010 six-1.16.0 soupsieve-2.5 stack-data-0.6.3 sympy-1.12 t5-0.9.4 tabulate-0.9.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.3 tensorflow-datasets-4.8.3 tensorflow-estimator-2.9.0 tensorflow-hub-0.16.1 tensorflow-io-gcs-filesystem-0.37.0 tensorflow-metadata-1.12.0 tensorflow-text-2.9.0 tensorstore-0.1.55 termcolor-2.4.0 terminado-0.18.1 tf-keras-2.15.0 tfds-nightly-4.8.3.dev202303280045 threadpoolctl-3.5.0 tinycss2-1.3.0 tokenizers-0.19.1 toml-0.10.2 tomli-2.0.1 toolz-0.12.1 tornado-6.4 tqdm-4.66.4 traitlets-5.14.3 transformers-4.41.1 typeguard-2.13.3 types-python-dateutil-2.9.0.20240316 tzdata-2024.1 uri-template-1.3.0 urllib3-2.2.1 utilsforecast-0.1.10 wcwidth-0.2.13 webcolors-1.13 webencodings-0.5.1 websocket-client-1.8.0 werkzeug-3.0.3 widgetsnbextension-4.0.10 wrapt-1.16.0 zipp-3.18.2\n",
            "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "\u001b[0m\u001b[91m\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: pip install --upgrade pip\n",
            "\u001b[0mRemoving intermediate container f67b582310b3\n",
            " ---> 921d88a323c8\n",
            "Step 4/8 : COPY timesfm_serving/ /app\n",
            " ---> a06409b6560a\n",
            "Step 5/8 : RUN git clone https://github.com/google-research/timesfm.git\n",
            " ---> Running in 571dd64e1aa4\n",
            "\u001b[91mCloning into 'timesfm'...\n",
            "\u001b[0mRemoving intermediate container 571dd64e1aa4\n",
            " ---> 49c7e94393c6\n",
            "Step 6/8 : RUN rm timesfm/__init__.py\n",
            " ---> Running in 637ae899a7e8\n",
            "Removing intermediate container 637ae899a7e8\n",
            " ---> 312fa85463bc\n",
            "Step 7/8 : RUN sed -i 's#^from src#from .#g' timesfm/src/timesfm.py\n",
            " ---> Running in 995be9d195a9\n",
            "Removing intermediate container 995be9d195a9\n",
            " ---> e4c1002cbc08\n",
            "Step 8/8 : CMD [\"python\", \"main.py\"]\n",
            " ---> Running in 0589af10ce7d\n",
            "Removing intermediate container 0589af10ce7d\n",
            " ---> 7506935aa657\n",
            "Successfully built 7506935aa657\n",
            "Successfully tagged us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m:latest\n",
            "PUSH\n",
            "Pushing us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m\n",
            "The push refers to repository [us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m]\n",
            "48548fa161b9: Preparing\n",
            "8e232fc6a4f4: Preparing\n",
            "2160814a19c9: Preparing\n",
            "78c3b9764d55: Preparing\n",
            "2ef22edebea9: Preparing\n",
            "059a541084b1: Preparing\n",
            "c693c81ba348: Preparing\n",
            "557222c7dbce: Preparing\n",
            "dea29dede57a: Preparing\n",
            "5f70bf18a086: Preparing\n",
            "19b2919547f9: Preparing\n",
            "c8c7004cad14: Preparing\n",
            "d26a05b398ec: Preparing\n",
            "ccdf5363c32f: Preparing\n",
            "c089cd8e039b: Preparing\n",
            "f8b912b0934e: Preparing\n",
            "11204877a559: Preparing\n",
            "7b4a7e75d6ce: Preparing\n",
            "b43c1d914be6: Preparing\n",
            "0a1f19c0d90d: Preparing\n",
            "a8273e3b1197: Preparing\n",
            "cbe4fb5e267b: Preparing\n",
            "734c0f0b65c2: Preparing\n",
            "8845ab872c1c: Preparing\n",
            "d7d4c2f9d26b: Preparing\n",
            "bbe1a212f7e9: Preparing\n",
            "059a541084b1: Waiting\n",
            "c693c81ba348: Waiting\n",
            "557222c7dbce: Waiting\n",
            "dea29dede57a: Waiting\n",
            "5f70bf18a086: Waiting\n",
            "19b2919547f9: Waiting\n",
            "c8c7004cad14: Waiting\n",
            "d26a05b398ec: Waiting\n",
            "ccdf5363c32f: Waiting\n",
            "c089cd8e039b: Waiting\n",
            "f8b912b0934e: Waiting\n",
            "11204877a559: Waiting\n",
            "7b4a7e75d6ce: Waiting\n",
            "b43c1d914be6: Waiting\n",
            "0a1f19c0d90d: Waiting\n",
            "a8273e3b1197: Waiting\n",
            "cbe4fb5e267b: Waiting\n",
            "734c0f0b65c2: Waiting\n",
            "8845ab872c1c: Waiting\n",
            "d7d4c2f9d26b: Waiting\n",
            "bbe1a212f7e9: Waiting\n",
            "78c3b9764d55: Pushed\n",
            "48548fa161b9: Pushed\n",
            "8e232fc6a4f4: Pushed\n",
            "2160814a19c9: Pushed\n",
            "059a541084b1: Pushed\n",
            "c693c81ba348: Pushed\n",
            "dea29dede57a: Pushed\n",
            "5f70bf18a086: Layer already exists\n",
            "557222c7dbce: Pushed\n",
            "19b2919547f9: Pushed\n",
            "c8c7004cad14: Pushed\n",
            "d26a05b398ec: Pushed\n",
            "ccdf5363c32f: Pushed\n",
            "f8b912b0934e: Pushed\n",
            "c089cd8e039b: Pushed\n",
            "7b4a7e75d6ce: Pushed\n",
            "11204877a559: Pushed\n",
            "0a1f19c0d90d: Pushed\n",
            "b43c1d914be6: Pushed\n",
            "cbe4fb5e267b: Pushed\n",
            "a8273e3b1197: Pushed\n",
            "d7d4c2f9d26b: Pushed\n",
            "8845ab872c1c: Pushed\n",
            "bbe1a212f7e9: Pushed\n",
            "734c0f0b65c2: Pushed\n",
            "2ef22edebea9: Pushed\n",
            "latest: digest: sha256:ae941bfe39a080ac21a60c3f781c92b7cbee7f59429fd0e25aa1607d95604766 size: 5754\n",
            "DONE\n",
            "\n",
            "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                IMAGES                                                                                   STATUS\n",
            "0e3254ec-7ca6-4c6c-9d4b-e6eb1727cb63  2024-05-24T01:23:15+00:00  7M30S     gs://argolis-project-340214_cloudbuild/source/1716513794.648469-5b9660f810954df8aa352c2e483d6291.tgz  us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m (+1 more)  SUCCESS\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $TIMESFM_IMAGE_URI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5tof6IIWOi-",
        "outputId": "85332bec-5230-449f-b659-5356949245a0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEPLOY_IMAGE = \"https://cloudbuild.googleapis.com/v1/projects/argolis-project-340214/locations/global/builds/0e3254ec-7ca6-4c6c-9d4b-e6eb1727cb63\""
      ],
      "metadata": {
        "id": "WWCShMTxXR_Y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run the container locally\n",
        "local_model = LocalModel(\n",
        "    serving_container_image_uri=TIMESFM_IMAGE_URI,\n",
        "    serving_container_predict_route=DEFAULT_PREDICT_ROUTE,\n",
        "    serving_container_health_route=DEFAULT_HEALTH_ROUTE,\n",
        "    serving_container_ports=[DEFAULT_HTTP_PORT],\n",
        ")"
      ],
      "metadata": {
        "id": "RBzB5prl5IPX"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_model.get_serving_container_spec()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bur9wb2A5DP9",
        "outputId": "56473f28-8622-41de-a2a2-4f27bcc82084"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "image_uri: \"us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m\"\n",
              "ports {\n",
              "  container_port: 8501\n",
              "}\n",
              "predict_route: \"/predict\"\n",
              "health_route: \"/health\""
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [list(np.linspace(0, 1, 100)), list(np.sin(np.linspace(0, 20, 200)))]\n",
        "payload = {\"instances\": [{\"inputs\": inputs}]}\n",
        "\n",
        "with open('payload.json', 'w') as f:\n",
        "    json.dump(payload, f)"
      ],
      "metadata": {
        "id": "H2W_uJnqQKTS"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo service docker restart"
      ],
      "metadata": {
        "id": "1RhU7MDIRqkc"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "print(\"aiplatform version: \", aiplatform.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uNpxMOLSOvo",
        "outputId": "ba7a118f-74ce-460d-9b6e-7f87b4d32454"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aiplatform version:  1.52.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_COLAB = False\n",
        "if \"google.colab\" in sys.modules:\n",
        "  IS_COLAB = True\n",
        "#%%bash -s $IS_COLAB $DEPLOY_IMAGE $TIMESFM_IMAGE_URI\n"
      ],
      "metadata": {
        "id": "8cPcgX2KYF5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TIMESFM_IMAGE_URI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "45HSSZokZs40",
        "outputId": "86ffa450-eea3-41c7-9172-b795c9e40810"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!TIMESFM_IMAGE_URI=$TIMESFM_IMAGE_URI\n",
        "!DEPLOY_IMAGE=$DEPLOY_IMAGE\n"
      ],
      "metadata": {
        "id": "7Mn8Apj4Y-Rb"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash -s $TIMESFM_IMAGE_URI $DEPLOY_IMAGE\n",
        "set -x\n",
        "echo \"Got param1 as:\" $1\n",
        "echo \"Got param2 as:\" $2\n",
        "dockerd -b none --iptables=0 -l warn &\n",
        "for i in $(seq 5); do [ ! -S \"/var/run/docker.sock\" ] && sleep 2 || break; done\n",
        "docker pull $1\n",
        "docker tag $1 $2\n",
        "docker push $2\n",
        "kill $(jobs -p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QLa4REPTJND",
        "outputId": "831d0ca4-8026-4931-c3a5-942e09a08113"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got param1 as: us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m\n",
            "Got param2 as: https://cloudbuild.googleapis.com/v1/projects/argolis-project-340214/locations/global/builds/0e3254ec-7ca6-4c6c-9d4b-e6eb1727cb63\n",
            "Using default tag: latest\n",
            "latest: Pulling from argolis-project-340214/googleio24/timesfm-001-200m\n",
            "c6cf28de8a06: Already exists\n",
            "891494355808: Already exists\n",
            "6582c62583ef: Already exists\n",
            "bf2c3e352f3d: Already exists\n",
            "a99509a32390: Already exists\n",
            "946285778af4: Already exists\n",
            "b2ab5d29389b: Already exists\n",
            "d76e704b1be9: Already exists\n",
            "32b14c58fcfc: Already exists\n",
            "49c9ff2efd6b: Already exists\n",
            "5119e73f1536: Already exists\n",
            "b82c8e4a85c6: Already exists\n",
            "30c0e033ca4b: Already exists\n",
            "88ccd20b36d3: Already exists\n",
            "abf00b58c1b0: Pulling fs layer\n",
            "8e6b754449a4: Pulling fs layer\n",
            "4f4fb700ef54: Pulling fs layer\n",
            "12eeb765d0fa: Pulling fs layer\n",
            "9bab74df5c6b: Pulling fs layer\n",
            "e64e5e7eb223: Pulling fs layer\n",
            "e4f838478090: Pulling fs layer\n",
            "74e15fee10a2: Pulling fs layer\n",
            "af22d1c1dda2: Pulling fs layer\n",
            "50fbc783d0e0: Pulling fs layer\n",
            "369dd2ab46b3: Pulling fs layer\n",
            "6df29dd829f6: Pulling fs layer\n",
            "e4f838478090: Waiting\n",
            "74e15fee10a2: Waiting\n",
            "af22d1c1dda2: Waiting\n",
            "50fbc783d0e0: Waiting\n",
            "369dd2ab46b3: Waiting\n",
            "12eeb765d0fa: Waiting\n",
            "9bab74df5c6b: Waiting\n",
            "e64e5e7eb223: Waiting\n",
            "6df29dd829f6: Waiting\n",
            "4f4fb700ef54: Verifying Checksum\n",
            "4f4fb700ef54: Download complete\n",
            "abf00b58c1b0: Verifying Checksum\n",
            "abf00b58c1b0: Download complete\n",
            "8e6b754449a4: Verifying Checksum\n",
            "8e6b754449a4: Download complete\n",
            "12eeb765d0fa: Verifying Checksum\n",
            "12eeb765d0fa: Download complete\n",
            "e64e5e7eb223: Verifying Checksum\n",
            "e64e5e7eb223: Download complete\n",
            "e4f838478090: Verifying Checksum\n",
            "e4f838478090: Download complete\n",
            "9bab74df5c6b: Verifying Checksum\n",
            "9bab74df5c6b: Download complete\n",
            "af22d1c1dda2: Verifying Checksum\n",
            "af22d1c1dda2: Download complete\n",
            "50fbc783d0e0: Verifying Checksum\n",
            "50fbc783d0e0: Download complete\n",
            "369dd2ab46b3: Verifying Checksum\n",
            "369dd2ab46b3: Download complete\n",
            "6df29dd829f6: Verifying Checksum\n",
            "6df29dd829f6: Download complete\n",
            "abf00b58c1b0: Pull complete\n",
            "8e6b754449a4: Pull complete\n",
            "4f4fb700ef54: Pull complete\n",
            "74e15fee10a2: Verifying Checksum\n",
            "74e15fee10a2: Download complete\n",
            "12eeb765d0fa: Pull complete\n",
            "9bab74df5c6b: Pull complete\n",
            "e64e5e7eb223: Pull complete\n",
            "e4f838478090: Pull complete\n",
            "74e15fee10a2: Pull complete\n",
            "af22d1c1dda2: Pull complete\n",
            "50fbc783d0e0: Pull complete\n",
            "369dd2ab46b3: Pull complete\n",
            "6df29dd829f6: Pull complete\n",
            "Digest: sha256:ae941bfe39a080ac21a60c3f781c92b7cbee7f59429fd0e25aa1607d95604766\n",
            "Status: Downloaded newer image for us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m:latest\n",
            "us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m:latest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "+ echo 'Got param1 as:' us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m\n",
            "+ echo 'Got param2 as:' https://cloudbuild.googleapis.com/v1/projects/argolis-project-340214/locations/global/builds/0e3254ec-7ca6-4c6c-9d4b-e6eb1727cb63\n",
            "++ seq 5\n",
            "+ for i in $(seq 5)\n",
            "+ '[' '!' -S /var/run/docker.sock ']'\n",
            "+ sleep 2\n",
            "+ dockerd -b none --iptables=0 -l warn\n",
            "time=\"2024-05-24T02:28:21.838829849Z\" level=warning msg=\"failed to load plugin io.containerd.snapshotter.v1.devmapper\" error=\"devmapper not configured\"\n",
            "time=\"2024-05-24T02:28:21.839344540Z\" level=warning msg=\"could not use snapshotter devmapper in metadata plugin\" error=\"devmapper not configured\"\n",
            "time=\"2024-05-24T02:28:21.841938820Z\" level=error msg=\"failed to initialize a tracing processor \\\"otlp\\\"\" error=\"no OpenTelemetry endpoint: skip plugin\"\n",
            "time=\"2024-05-24T02:28:21.887473307Z\" level=error msg=\"failed to mount overlay: invalid argument\" storage-driver=overlay2\n",
            "time=\"2024-05-24T02:28:21.887602376Z\" level=error msg=\"exec: \\\"fuse-overlayfs\\\": executable file not found in $PATH\" storage-driver=fuse-overlayfs\n",
            "time=\"2024-05-24T02:28:21.919831641Z\" level=warning msg=\"Failed to disable IPv6 on all interfaces on network namespace \\\"/var/run/docker/netns/65678b632bca\\\": failed to disable IPv6 forwarding for container's interface all: open /proc/sys/net/ipv6/conf/all/disable_ipv6: read-only file system\"\n",
            "time=\"2024-05-24T02:28:21.920152565Z\" level=error msg=\"failed to create osl sandbox while trying to restore sandbox 65678b6 for cleanup: operation not permitted\"\n",
            "time=\"2024-05-24T02:28:21.937188913Z\" level=warning msg=\"WARNING: No swap limit support\"\n",
            "+ for i in $(seq 5)\n",
            "+ '[' '!' -S /var/run/docker.sock ']'\n",
            "+ break\n",
            "+ docker pull us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m\n",
            "+ docker tag us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m https://cloudbuild.googleapis.com/v1/projects/argolis-project-340214/locations/global/builds/0e3254ec-7ca6-4c6c-9d4b-e6eb1727cb63\n",
            "Error parsing reference: \"https://cloudbuild.googleapis.com/v1/projects/argolis-project-340214/locations/global/builds/0e3254ec-7ca6-4c6c-9d4b-e6eb1727cb63\" is not a valid repository/tag: invalid reference format\n",
            "+ docker push https://cloudbuild.googleapis.com/v1/projects/argolis-project-340214/locations/global/builds/0e3254ec-7ca6-4c6c-9d4b-e6eb1727cb63\n",
            "invalid reference format\n",
            "++ jobs -p\n",
            "+ kill 83663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dockerstart.sh\n",
        "nohup dockerd -b none --iptables=0 -l warn &\n",
        "#cat /var/run/docker.sock"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X70zVJYtgd_",
        "outputId": "6737c15c-afa0-4722-c4e1-27152187be04"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dockerstart.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "chmod +x dockerstart.sh\n",
        "./dockerstart.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUxDFq02EaLn",
        "outputId": "c087fc86-8565-421c-9492-5714ab474000"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process is interrupted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "ps -ef | grep docker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_3VkQWewohb",
        "outputId": "8897ed9e-d1c4-4bd3-e6ba-fbfd0b7e2feb"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root           1       0  0 15:49 ?        00:00:01 /sbin/docker-init -- /datalab/run.sh\n",
            "root      113976  113974  0 23:22 ?        00:00:00 grep docker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%bash -s $TIMESFM_IMAGE_URI $DEPLOY_IMAGE\n",
        "set -x\n",
        "echo \"Got param1 as:\" $1\n",
        "echo \"Got param2 as:\" $2\n",
        "dockerd -b none --iptables=0 -l warn &\n",
        "for i in $(seq 5); do [ ! -S \"/var/run/docker.sock\" ] && sleep 2 || break; done\n",
        "docker pull $1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stInjdOHokae",
        "outputId": "63608ae4-1f10-4f38-ff5e-ca08600f44ba"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process is interrupted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = local_model.deploy_to_local_endpoint(    artifact_uri=f'{GCS_TIMESFM_CKPT_PATH}/checkpoints',\n",
        "    host_port=DEFAULT_HTTP_PORT)"
      ],
      "metadata": {
        "id": "5wJ-Dk5vnOUZ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/var/run/docker.sock\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nKdNx2UojT8",
        "outputId": "b2061856-5766-4a18-df05-e34cd74ce63e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/var/run/docker.sock': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#endpoint.artifact_uri = f'{GCS_TIMESFM_CKPT_PATH}/checkpoints'\n",
        "print(\"Serve:\", endpoint.serve())\n",
        "print(endpoint.artifact_uri,\n",
        "endpoint.container_port,\n",
        "endpoint.container_is_running,\n",
        "      endpoint.run_health_check())"
      ],
      "metadata": {
        "id": "h1Q0OLSKnS5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with local_model.deploy_to_local_endpoint(\n",
        "    artifact_uri=f'{GCS_TIMESFM_CKPT_PATH}/checkpoints',\n",
        "    host_port=DEFAULT_HTTP_PORT\n",
        ") as local_endpoint:\n",
        "\n",
        "    health_check_response = local_endpoint.run_health_check()\n",
        "    predict_response = local_endpoint.predict(\n",
        "        request_file='payload.json',\n",
        "        headers={\"Content-Type\": \"application/json\"}\n",
        "    )"
      ],
      "metadata": {
        "id": "HOmBtqOlQQhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "sudo apt update -qq\n",
        "\n",
        "sudo apt install apt-transport-https ca-certificates curl software-properties-common -qq\n",
        "\n",
        "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n",
        "\n",
        "sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\" &\n",
        "\n",
        "sudo apt update -qq\n",
        "\n",
        "sudo apt install docker-ce\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co9VZPxN0XkG",
        "outputId": "520742f1-8ef3-4005-f21e-3437c0946aaa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "ca-certificates is already the newest version (20230311ubuntu0.22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.16).\n",
            "software-properties-common is already the newest version (0.99.22.9).\n",
            "The following NEW packages will be installed:\n",
            "  apt-transport-https\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 1,510 B of archives.\n",
            "After this operation, 170 kB of additional disk space will be used.\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package apt-transport-https.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../apt-transport-https_2.4.12_all.deb ...\n",
            "Unpacking apt-transport-https (2.4.12) ...\n",
            "Setting up apt-transport-https (2.4.12) ...\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "Repository: 'deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable'\n",
            "Description:\n",
            "Archive for codename: bionic components: stable\n",
            "More info: https://download.docker.com/linux/ubuntu\n",
            "Adding repository.\n",
            "Adding deb entry to /etc/apt/sources.list.d/archive_uri-https_download_docker_com_linux_ubuntu-jammy.list\n",
            "Adding disabled deb-src entry to /etc/apt/sources.list.d/archive_uri-https_download_docker_com_linux_ubuntu-jammy.list\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Get:2 https://download.docker.com/linux/ubuntu bionic InRelease [64.4 kB]\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:12 https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages [46.4 kB]\n",
            "Fetched 111 kB in 3s (35.5 kB/s)\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "W: https://download.docker.com/linux/ubuntu/dists/bionic/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor containerd.io docker-buildx-plugin docker-ce-cli\n",
            "  docker-ce-rootless-extras docker-compose-plugin iptables libip6tc2\n",
            "  libnetfilter-conntrack3 libnfnetlink0 libnftnl11 libslirp0 netbase pigz\n",
            "  slirp4netns\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils aufs-tools cgroupfs-mount\n",
            "  | cgroup-lite firewalld nftables\n",
            "The following NEW packages will be installed:\n",
            "  apparmor containerd.io docker-buildx-plugin docker-ce docker-ce-cli\n",
            "  docker-ce-rootless-extras docker-compose-plugin iptables libip6tc2\n",
            "  libnetfilter-conntrack3 libnfnetlink0 libnftnl11 libslirp0 netbase pigz\n",
            "  slirp4netns\n",
            "0 upgraded, 16 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 112 MB of archives.\n",
            "After this operation, 407 MB of additional disk space will be used.\n",
            "Get:1 https://download.docker.com/linux/ubuntu bionic/stable amd64 containerd.io amd64 1.6.21-1 [28.3 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pigz amd64 2.6-1 [63.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 netbase all 6.3 [12.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.3 [595 kB]\n",
            "Get:5 https://download.docker.com/linux/ubuntu bionic/stable amd64 docker-buildx-plugin amd64 0.10.5-1~ubuntu.18.04~bionic [26.1 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libip6tc2 amd64 1.8.7-1ubuntu5.2 [20.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnfnetlink0 amd64 1.0.1-3build3 [14.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnetfilter-conntrack3 amd64 1.0.9-1 [45.3 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnftnl11 amd64 1.2.1-1build1 [65.5 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 iptables amd64 1.8.7-1ubuntu5.2 [455 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libslirp0 amd64 4.6.1-1build1 [61.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/universe amd64 slirp4netns amd64 1.0.1-2 [28.2 kB]\n",
            "Get:13 https://download.docker.com/linux/ubuntu bionic/stable amd64 docker-ce-cli amd64 5:24.0.2-1~ubuntu.18.04~bionic [13.3 MB]\n",
            "Get:14 https://download.docker.com/linux/ubuntu bionic/stable amd64 docker-ce amd64 5:24.0.2-1~ubuntu.18.04~bionic [22.9 MB]\n",
            "Get:15 https://download.docker.com/linux/ubuntu bionic/stable amd64 docker-ce-rootless-extras amd64 5:24.0.2-1~ubuntu.18.04~bionic [9,014 kB]\n",
            "Get:16 https://download.docker.com/linux/ubuntu bionic/stable amd64 docker-compose-plugin amd64 2.18.1-1~ubuntu.18.04~bionic [10.9 MB]\n",
            "Fetched 112 MB in 2s (64.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 16.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pigz.\n",
            "(Reading database ... 121922 files and directories currently installed.)\n",
            "Preparing to unpack .../00-pigz_2.6-1_amd64.deb ...\n",
            "Unpacking pigz (2.6-1) ...\n",
            "Selecting previously unselected package netbase.\n",
            "Preparing to unpack .../01-netbase_6.3_all.deb ...\n",
            "Unpacking netbase (6.3) ...\n",
            "Selecting previously unselected package apparmor.\n",
            "Preparing to unpack .../02-apparmor_3.0.4-2ubuntu2.3_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.3) ...\n",
            "Selecting previously unselected package libip6tc2:amd64.\n",
            "Preparing to unpack .../03-libip6tc2_1.8.7-1ubuntu5.2_amd64.deb ...\n",
            "Unpacking libip6tc2:amd64 (1.8.7-1ubuntu5.2) ...\n",
            "Selecting previously unselected package libnfnetlink0:amd64.\n",
            "Preparing to unpack .../04-libnfnetlink0_1.0.1-3build3_amd64.deb ...\n",
            "Unpacking libnfnetlink0:amd64 (1.0.1-3build3) ...\n",
            "Selecting previously unselected package libnetfilter-conntrack3:amd64.\n",
            "Preparing to unpack .../05-libnetfilter-conntrack3_1.0.9-1_amd64.deb ...\n",
            "Unpacking libnetfilter-conntrack3:amd64 (1.0.9-1) ...\n",
            "Selecting previously unselected package libnftnl11:amd64.\n",
            "Preparing to unpack .../06-libnftnl11_1.2.1-1build1_amd64.deb ...\n",
            "Unpacking libnftnl11:amd64 (1.2.1-1build1) ...\n",
            "Selecting previously unselected package iptables.\n",
            "Preparing to unpack .../07-iptables_1.8.7-1ubuntu5.2_amd64.deb ...\n",
            "Unpacking iptables (1.8.7-1ubuntu5.2) ...\n",
            "Selecting previously unselected package containerd.io.\n",
            "Preparing to unpack .../08-containerd.io_1.6.21-1_amd64.deb ...\n",
            "Unpacking containerd.io (1.6.21-1) ...\n",
            "Selecting previously unselected package docker-buildx-plugin.\n",
            "Preparing to unpack .../09-docker-buildx-plugin_0.10.5-1~ubuntu.18.04~bionic_amd64.deb ...\n",
            "Unpacking docker-buildx-plugin (0.10.5-1~ubuntu.18.04~bionic) ...\n",
            "Selecting previously unselected package docker-ce-cli.\n",
            "Preparing to unpack .../10-docker-ce-cli_5%3a24.0.2-1~ubuntu.18.04~bionic_amd64.deb ...\n",
            "Unpacking docker-ce-cli (5:24.0.2-1~ubuntu.18.04~bionic) ...\n",
            "Selecting previously unselected package docker-ce.\n",
            "Preparing to unpack .../11-docker-ce_5%3a24.0.2-1~ubuntu.18.04~bionic_amd64.deb ...\n",
            "Unpacking docker-ce (5:24.0.2-1~ubuntu.18.04~bionic) ...\n",
            "Selecting previously unselected package docker-ce-rootless-extras.\n",
            "Preparing to unpack .../12-docker-ce-rootless-extras_5%3a24.0.2-1~ubuntu.18.04~bionic_amd64.deb ...\n",
            "Unpacking docker-ce-rootless-extras (5:24.0.2-1~ubuntu.18.04~bionic) ...\n",
            "Selecting previously unselected package docker-compose-plugin.\n",
            "Preparing to unpack .../13-docker-compose-plugin_2.18.1-1~ubuntu.18.04~bionic_amd64.deb ...\n",
            "Unpacking docker-compose-plugin (2.18.1-1~ubuntu.18.04~bionic) ...\n",
            "Selecting previously unselected package libslirp0:amd64.\n",
            "Preparing to unpack .../14-libslirp0_4.6.1-1build1_amd64.deb ...\n",
            "Unpacking libslirp0:amd64 (4.6.1-1build1) ...\n",
            "Selecting previously unselected package slirp4netns.\n",
            "Preparing to unpack .../15-slirp4netns_1.0.1-2_amd64.deb ...\n",
            "Unpacking slirp4netns (1.0.1-2) ...\n",
            "Setting up libip6tc2:amd64 (1.8.7-1ubuntu5.2) ...\n",
            "Setting up libnftnl11:amd64 (1.2.1-1build1) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up docker-buildx-plugin (0.10.5-1~ubuntu.18.04~bionic) ...\n",
            "Setting up containerd.io (1.6.21-1) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/containerd.service → /lib/systemd/system/containerd.service.\n",
            "Setting up docker-compose-plugin (2.18.1-1~ubuntu.18.04~bionic) ...\n",
            "Setting up docker-ce-cli (5:24.0.2-1~ubuntu.18.04~bionic) ...\n",
            "Setting up libslirp0:amd64 (4.6.1-1build1) ...\n",
            "Setting up pigz (2.6-1) ...\n",
            "Setting up libnfnetlink0:amd64 (1.0.1-3build3) ...\n",
            "Setting up netbase (6.3) ...\n",
            "Setting up docker-ce-rootless-extras (5:24.0.2-1~ubuntu.18.04~bionic) ...\n",
            "Setting up slirp4netns (1.0.1-2) ...\n",
            "Setting up libnetfilter-conntrack3:amd64 (1.0.9-1) ...\n",
            "Setting up iptables (1.8.7-1ubuntu5.2) ...\n",
            "update-alternatives: using /usr/sbin/iptables-legacy to provide /usr/sbin/iptables (iptables) in auto mode\n",
            "update-alternatives: using /usr/sbin/ip6tables-legacy to provide /usr/sbin/ip6tables (ip6tables) in auto mode\n",
            "update-alternatives: using /usr/sbin/iptables-nft to provide /usr/sbin/iptables (iptables) in auto mode\n",
            "update-alternatives: using /usr/sbin/ip6tables-nft to provide /usr/sbin/ip6tables (ip6tables) in auto mode\n",
            "update-alternatives: using /usr/sbin/arptables-nft to provide /usr/sbin/arptables (arptables) in auto mode\n",
            "update-alternatives: using /usr/sbin/ebtables-nft to provide /usr/sbin/ebtables (ebtables) in auto mode\n",
            "Setting up docker-ce (5:24.0.2-1~ubuntu.18.04~bionic) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /lib/systemd/system/docker.service.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/docker.socket → /lib/systemd/system/docker.socket.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo dockerd\n",
        "#!systemctl status docker\n",
        "#!sudo systemctl start docker\n",
        "#!docker build -t my-image ."
      ],
      "metadata": {
        "id": "V9WWG8Al-wsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%shell\n",
        "\n",
        "!TIMESFM_IMAGE_URI=$TIMESFM_IMAGE_URI\n",
        "!echo $TIMESFM_IMAGE_URI\n",
        "#!dockerd -b none --iptables=0 -l warn &\n",
        "!dockerd -b none --iptables=0 -l warn &\n",
        "!docker  build --tag=$TIMESFM_IMAGE_URI ./src/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFFpyMH_2hev",
        "outputId": "eda09c8e-34f6-4dd1-cbf1-9eefcb1837af"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m\n",
            "\u001b[33mWARN\u001b[0m[2024-05-24T00:19:56.633298637Z] failed to load plugin io.containerd.snapshotter.v1.devmapper  \u001b[33merror\u001b[0m=\"devmapper not configured\"\n",
            "\u001b[33mWARN\u001b[0m[2024-05-24T00:19:56.634507569Z] could not use snapshotter devmapper in metadata plugin  \u001b[33merror\u001b[0m=\"devmapper not configured\"\n",
            "\u001b[31mERRO\u001b[0m[2024-05-24T00:19:56.636233559Z] failed to initialize a tracing processor \"otlp\"  \u001b[31merror\u001b[0m=\"no OpenTelemetry endpoint: skip plugin\"\n",
            "\u001b[31mERRO\u001b[0m[2024-05-24T00:19:56.673711133Z] failed to mount overlay: invalid argument     \u001b[31mstorage-driver\u001b[0m=overlay2\n",
            "\u001b[31mERRO\u001b[0m[2024-05-24T00:19:56.673884998Z] exec: \"fuse-overlayfs\": executable file not found in $PATH  \u001b[31mstorage-driver\u001b[0m=fuse-overlayfs\n",
            "\u001b[33mWARN\u001b[0m[2024-05-24T00:19:56.715004047Z] Failed to disable IPv6 on all interfaces on network namespace \"/var/run/docker/netns/65678b632bca\": failed to disable IPv6 forwarding for container's interface all: open /proc/sys/net/ipv6/conf/all/disable_ipv6: read-only file system \n",
            "\u001b[31mERRO\u001b[0m[2024-05-24T00:19:56.715250854Z] failed to create osl sandbox while trying to restore sandbox 65678b6 for cleanup: operation not permitted \n",
            "\u001b[33mWARN\u001b[0m[2024-05-24T00:19:56.733782536Z] WARNING: No swap limit support               \n",
            "ERROR: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check version.\n",
        "!docker --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kXInAGBxrQu",
        "outputId": "aeeaf799-deea-46e0-d557-fea1e013bfb0"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Docker version 24.0.2, build cb74dfc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!docker  build --tag=$TIMESFM_IMAGE_URI ./src/"
      ],
      "metadata": {
        "id": "rTU6tX8N274x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "pip install udocker\n",
        "udocker --allow-root install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TVFpR6LvAtC",
        "outputId": "e09d2344-19b9-401c-b75d-77842110ec4d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting udocker\n",
            "  Downloading udocker-1.3.16-py2.py3-none-any.whl (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: udocker\n",
            "Successfully installed udocker-1.3.16\n",
            "Info: creating repo: /root/.udocker\n",
            "Info: udocker command line interface 1.3.16\n",
            "Info: searching for udockertools >= 1.2.11\n",
            "Info: installing udockertools 1.2.11\n",
            "Info: installation of udockertools successful\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "set -x\n",
        "dockerd -b none --iptables=0 -l warn &\n",
        "for i in $(seq 5); do [ ! -S \"/var/run/docker.sock\" ] && sleep 2 || break; done\n",
        "docker info\n",
        "docker network ls\n",
        "docker pull hello-world\n",
        "docker images\n",
        "docker run hello-world\n",
        "kill $(jobs -p)"
      ],
      "metadata": {
        "id": "KGPV1vYzwDUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run on Vertex AI Using Vertex AI Model Registry\n",
        "\n",
        "local_model.push_image()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "J2gyK88jFqo_",
        "outputId": "179082ae-a390-4b54-b44e-d3a7dd5d579f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DockerError",
          "evalue": "('\\nDocker failed with error code 1.\\nCommand: docker push us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m\\n', ['docker', 'push', 'us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m'], 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDockerError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-cf18877b8392>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Run on Vertex AI Using Vertex AI Model Registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlocal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/prediction/local_model.py\u001b[0m in \u001b[0;36mpush_image\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mreturn_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_docker_error_with_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpull_image_if_not_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/docker_utils/errors.py\u001b[0m in \u001b[0;36mraise_docker_error_with_command\u001b[0;34m(command, return_code)\u001b[0m\n\u001b[1;32m     58\u001b[0m         )\n\u001b[1;32m     59\u001b[0m     )\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mDockerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mDockerError\u001b[0m: ('\\nDocker failed with error code 1.\\nCommand: docker push us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m\\n', ['docker', 'push', 'us-central1-docker.pkg.dev/argolis-project-340214/googleio24/timesfm-001-200m'], 1)"
          ]
        }
      ]
    }
  ]
}